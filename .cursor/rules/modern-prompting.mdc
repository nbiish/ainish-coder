---
description: Use the deliberate tool for a comprehensive cognitive strategies framework.
alwaysApply: false
---
# Modern Prompting & Context Engineering Framework

## Compression Principles

- Conciseness is clarity
- Select essential techniques only
- Multiple strategies available for selection

## Core Cognitive Framework

### OOReDAct

**Purpose:** Deep deliberation before action/decision

Required structure:

```markdown
<observe>
Synthesize [[facts]] and [[observations]]
</observe>

<orient>
understand [[knowledge]] and [[context]]
</orient>

<reason strategy="[[Strategy Name]]">
[[Strategy-specific reasoning - see strategies below]]
</reason>

<decide>
State next [[action]] or final [[response]]
</decide>

<act-plan>
Plan next [[action]] or final [[response]] steps
</act-plan>
```

## REASONING STRATEGIES

### Chain-of-Thought (CoT)

CoT prompting encourages language models to articulate their reasoning processes by breaking down complex problems into intermediate steps. Significantly enhances performance on tasks requiring logical reasoning, such as arithmetic and commonsense questions. Research demonstrates that prompting a 540-billion-parameter language model with CoT exemplars achieved state-of-the-art accuracy on the GSM8K benchmark for math word problems, surpassing even fine-tuned models with verifiers.

#### Visual Representation

```mermaid
graph TD
    A[Input Problem] --> B[Step 1: Identify Key Elements]
    B --> C[Step 2: Break Down Components]
    C --> D[Step 3: Apply Logic/Reasoning]
    D --> E[Step 4: Synthesize Information]
    E --> F[Step 5: Generate Answer]
```

**Flow Diagram:**
```
Input → [Analyze] → [Decompose] → [Reason] → [Synthesize] → Output
  ↓         ↓           ↓          ↓          ↓
Problem → Elements → Components → Logic → Answer
```

### Chain of Draft (CoD)

Iterative summarization technique designed to create information-dense summaries by progressively incorporating key entities and details while removing fluff. Produces executive-level summaries devoid of marketing jargon or filler text, ensuring every sentence carries significant informational weight.

#### Visual Representation

```mermaid
graph LR
    A[Input Text] --> B[Draft 1: Basic Summary]
    B --> C[Draft 2: Add Key Entities]
    C --> D[Draft 3: Remove Fluff]
    D --> E[Draft 4: Density Check]
    E --> F[Final: Executive Summary]
```

**Compression Flow:**
```
Original → [Extract] → [Densify] → [Refine] → [Validate] → Executive Summary
  100%       ↓           ↓          ↓          ↓
           Key Info → Entities → Remove → Density → 20% Size
```

### Cache-Augmented Reasoning + ReAct

Combines reasoning with acting (decision making), integrating reasoning with real-time decision-making. Enables models to interact with external environments while thinking through their decisions. Creates more capable AI agents that can use tools and APIs to accomplish complex tasks.

#### Visual Representation

```mermaid
graph TD
    A[Input Task] --> B[Cache: Preload Context]
    B --> C[Reason: Analyze Task]
    C --> D[Act: Execute Action]
    D --> E[Observe: Get Result]
    E --> F{More Actions?}
    F -->|Yes| C
    F -->|No| G[Final Output]

    H[Working Memory] -.-> C
    I[External Tools/APIs] -.-> D
```

**ReAct Cycle:**
```
Input → [Cache] → [Reason] → [Act] → [Observe] → [Decide] → Output
  ↓        ↓         ↓        ↓        ↓         ↓
Task → Context → Analysis → Action → Result → Continue?
```

**Memory Architecture:**
```
┌─────────────────┐    ┌─────────────────┐
│   Short-term    │    │   Long-term     │
│   Memory        │    │   Memory        │
│   (Session)     │    │   (Preferences) │
└─────────────────┘    └─────────────────┘
         │                       │
         └─────── Working Memory ────────┘
```

### Self-Consistency

Decoding strategy that enhances accuracy of reasoning tasks by generating multiple diverse reasoning paths for the same problem and selecting the most consistent answer through aggregation, typically a majority vote. Significantly improves performance on arithmetic, commonsense, and symbolic reasoning benchmarks compared to standard CoT prompting. However, computationally intensive as it requires multiple inference runs per input.

#### Visual Representation

```mermaid
graph TD
    A[Input Problem] --> B[Path 1: Reasoning A]
    A --> C[Path 2: Reasoning B]
    A --> D[Path 3: Reasoning C]
    
    B --> E[Answer A]
    C --> F[Answer B]
    D --> G[Answer C]
    
    E --> H[Majority Vote]
    F --> H
    G --> H
    
    H --> I[Final Consistent Answer]
```

**Parallel Processing:**
```
Input Problem
     ├── Path 1 → Answer A
     ├── Path 2 → Answer B
     └── Path 3 → Answer C
           ↓
    [Majority Vote] → Final Answer
```

**Consistency Matrix:**
```
Path 1: A → B → C → Answer X
Path 2: A → D → E → Answer X  ← Most Common
Path 3: A → F → G → Answer Y
        ↓
    Answer X (2/3 votes)
```

### PAL (Program-Aided Language)

Program-Aided Language Model approach that enhances reasoning abilities by generating executable code for computational tasks. Representative program-aided method alongside PoT (Program of Thought). Enables precise and deterministic computation via code execution, particularly advantageous for mathematical problems compared to potentially noisy retrieval methods.

#### Visual Representation

```mermaid
graph TD
    A[Problem Input] --> B[Generate Code]
    B --> C[Execute Code]
    C --> D[Get Result]
    D --> E[Minimal Rationale]
    E --> F[Final Answer]
    
    G[Code Environment] -.-> C
```

**PAL Workflow:**
```
Problem → [Code Gen] → [Execute] → [Result] → [Rationale] → Answer
   ↓         ↓          ↓         ↓         ↓
Math → Function → Run → Value → "# PoT offload" → Final
```

**Code Example:**
```python
# PoT offload
def solve_problem():
    x = 5
    y = 10
    result = x * y + 3
    return result

answer = solve_problem()  # Result: 53
```

### Reflexion

Self-improvement mechanism that enables language models to learn from mistakes and refine approaches over time. Implements feedback loop where model reflects on previous attempts, identifies errors or suboptimal decisions, and incorporates insights into subsequent attempts. Comprises three components: actor (generating initial attempts), evaluator (assessing quality), and self-reflection process (analyzing failures). Achieved 91% accuracy on code generation tasks compared to 19% for baseline approaches.

#### Visual Representation

```mermaid
graph TD
    A[Input Task] --> B[Actor: Generate Attempt]
    B --> C[Evaluator: Assess Quality]
    C --> D{Confidence < 0.7?}
    D -->|Yes| E[Self-Reflection: Analyze Failures]
    D -->|No| F[Final Output]
    E --> G[Refine Approach]
    G --> B
```

**Reflexion Loop:**
```
Input → [Actor] → [Evaluator] → [Reflect] → [Refine] → [Actor] → Output
  ↓        ↓         ↓          ↓         ↓        ↓
Task → Generate → Assess → Analyze → Improve → Generate → Result
```

**Three Components:**
```
┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│   Actor     │    │  Evaluator  │    │ Reflection  │
│ (Generate)  │───▶│ (Assess)    │───▶│ (Analyze)   │
└─────────────┘    └─────────────┘    └─────────────┘
       ▲                                        │
       └──────────────── Refine ────────────────┘
```

**Performance Improvement:**
```
Baseline: 19% accuracy
Reflexion: 91% accuracy (4.8x improvement)
```

#### Visual Representation

```mermaid
graph TD
    A[Long Code] --> B[Memory Manager]
    B --> C[Token Parser]
    C --> D[Code Minifier]
    D --> E[Syntax Validator]
    E --> F[Minified Code]
    
    G[Model Distillation] -.-> B
    H[Tokenizer] -.-> C
```

**Compression Pipeline:**
```
Original → [Memory] → [Parse] → [Minify] → [Validate] → Minified
  100%       ↓         ↓         ↓         ↓
          Manager → 50% → 20% → Syntax → 5% Size
```

### ToT-lite (Tree of Thoughts)

Tree-of-Thought (ToT) reframes reasoning as search problem, organizing reasoning process into hierarchical tree structure. At each reasoning step, model proposes multiple candidate continuations, allowing exploration of different reasoning pathways before concluding. Enables model to look ahead or backtrack as needed, significantly improving problem-solving performance compared to linear methods like CoT. Particularly effective for complex tasks requiring strategic planning and multi-step reasoning.

#### Visual Representation

```mermaid
graph TD
    A[Root Problem] --> B[Thought 1]
    A --> C[Thought 2]
    A --> D[Thought 3]
    
    B --> E[Evaluation 1]
    B --> F[Evaluation 2]
    C --> G[Evaluation 3]
    C --> H[Evaluation 4]
    D --> I[Evaluation 5]
    
    E --> J[Best Path]
    F --> J
    G --> J
    H --> J
    I --> J
    
    J --> K[Final Answer]
```

**Tree Structure:**
```
        Problem
       /   |   \
   Thought1 Thought2 Thought3
     / \     / \     |
  Eval1 Eval2 Eval3 Eval4 Eval5
     \   \   /   /   /
      \   \ /   /   /
       \   \   /   /
        Best Path
           |
       Final Answer
```

**Search Process:**
```
Level 1: [Problem] → [Thought A, Thought B, Thought C]
Level 2: [Evaluate] → [Score A, Score B, Score C]
Level 3: [Select] → [Best Path] → [Answer]
```

**Bounded Exploration:**
```
Max Depth: 3 levels
Max Breadth: 3 thoughts per level
Total Paths: 3³ = 27 (bounded)
```

### Metacognitive Prompting (MP)

Meta-R1 framework decouples metacognitive system into distinct object- and meta-levels, implementing systematic three-stage process. Guides problem-solving through structured, human-like cognitive operations including goal clarification, decomposition, filtering, abstraction, and pattern recognition. Enables systematic step-by-step reasoning for complex multi-step tasks through introspective reasoning processes.

#### Visual Representation

```mermaid
graph TD
    A[Input Problem] --> B[1. Understand]
    B --> C[2. Judge]
    C --> D[3. Evaluate]
    D --> E[4. Decide]
    E --> F[5. Assess Confidence]
    F --> G{Confidence > 0.6?}
    G -->|Yes| H[Final Answer]
    G -->|No| I[Reflect & Refine]
    I --> B
```

**5-Stage Process:**
```
Input → [Understand] → [Judge] → [Evaluate] → [Decide] → [Assess] → Output
  ↓         ↓          ↓         ↓         ↓         ↓
Problem → Goal → Decompose → Filter → Abstract → Pattern → Answer
```

**Meta-Level Architecture:**
```
┌─────────────────┐    ┌─────────────────┐
│   Object Level  │    │   Meta Level    │
│ (Problem Space) │◄──►│ (Control Space) │
│                 │    │                 │
│ • Understand    │    │ • Monitor       │
│ • Judge         │    │ • Control       │
│ • Evaluate      │    │ • Reflect       │
│ • Decide        │    │ • Adjust        │
│ • Assess        │    │                 │
└─────────────────┘    └─────────────────┘
```

**Confidence Assessment:**
```
High Confidence (>0.8): Direct Answer
Medium Confidence (0.6-0.8): Proceed with Caution
Low Confidence (<0.6): Reflect & Refine
```

### Automated Prompt Optimization (APO)

Self-referential self-improvement via prompt evolution where system generates and evaluates prompt variations autonomously. Implements feedback loop where model assesses prompt performance and iteratively refines prompts based on success metrics. Reduces manual prompt engineering effort while maintaining or improving task performance through systematic prompt optimization.

#### Visual Representation

```mermaid
graph TD
    A[Initial Prompt] --> B[Generate Variations]
    B --> C[Test Performance]
    C --> D[Evaluate Metrics]
    D --> E{Improvement?}
    E -->|Yes| F[Select Best Prompt]
    E -->|No| G[Generate New Variations]
    F --> H[Final Optimized Prompt]
    G --> C
    
    I[Performance Metrics] -.-> D
    J[Expert Templates] -.-> B
```

**APO Loop:**
```
Initial → [Generate] → [Test] → [Evaluate] → [Select] → Optimized
  ↓         ↓         ↓         ↓         ↓
Prompt → Variations → Metrics → Best → Refined
```

**Optimization Process:**
```
Generation: Prompt A, Prompt B, Prompt C
Testing:    Score A, Score B, Score C
Selection:  Best Score → New Base
Refinement: Generate A1, A2, A3...
```

**Performance Tracking:**
```
Iteration 1: 70% accuracy
Iteration 2: 75% accuracy (+5%)
Iteration 3: 80% accuracy (+5%)
Iteration 4: 82% accuracy (+2%)
Convergence: 82% (optimal)
```

### Reflexive Analysis

Embed ethical, legal, and cultural considerations directly into reasoning processes. Enables responsible AI by evaluating outputs against established guidelines and ensuring contextually-aware generations that consider broader societal implications. Particularly important for high-stakes decisions where bias, fairness, and cultural sensitivity are critical factors.

#### Visual Representation

```mermaid
graph TD
    A[Input Request] --> B[Variable Validation]
    B --> C[Function Review]
    C --> D[Class Assessment]
    D --> E[Error Detection]
    E --> F[Code Compliance]
    F --> G{All Tests Pass?}
    G -->|Yes| H[Generate Response]
    G -->|No| I[Flag Errors]
    I --> J[Refactor Code]
    J --> B
    H --> K[Final Output]
    
    L[Code Standards] -.-> B
    M[Tools Framework] -.-> C
    N[Design Patterns] -.-> D
```

**Responsible Code Pipeline:**
```
Input → [Validate] → [Review] → [Assess] → [Detect] → [Comply] → Output
  ↓        ↓         ↓         ↓         ↓         ↓
Request → Variables → Functions → Classes → Errors → Approved → Response
```

**Multi-Dimensional Analysis:**
```
┌─────────────┐  ┌─────────────┐  ┌─────────────┐
│  Variables  │  │  Functions  │  │   Classes   │
│ Validation  │  │   Review    │  │ Assessment  │
└─────────────┘  └─────────────┘  └─────────────┘
       │                │                │
       └─────────── Error Detection ──────┘
                        │
                   [Approval Gate]
```

**Risk Assessment Matrix:**
```
High Risk:   System, Database, Security operations
Medium Risk: Business logic, Data processing
Low Risk:    Utilities, Helper functions
```

### Progressive-Hint Prompting (PHP)

Enables automatic multiple interactions between users and LLMs by using previously generated answers as hints to progressively guide toward correct answers. Orthogonal to CoT and self-consistency, making it easy to combine with state-of-the-art techniques for further performance improvement. Implements cumulative knowledge building through multi-turn interaction where each response informs subsequent reasoning.

#### Visual Representation

```mermaid
graph TD
    A[Initial Question] --> B[Generate Answer 1]
    B --> C[Use as Hint]
    C --> D[Generate Answer 2]
    D --> E[Use as Hint]
    E --> F[Generate Answer 3]
    F --> G[Converge to Final]
    
    H[Context Memory] -.-> C
    I[Context Memory] -.-> E
```

**Progressive Learning:**
```
Turn 1: Question → Answer A → [Store as Hint]
Turn 2: Question + Hint A → Answer B → [Store as Hint]
Turn 3: Question + Hint A + Hint B → Answer C → [Final]
```

**Cumulative Context:**
```
┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│   Turn 1    │    │   Turn 2    │    │   Turn 3    │
│             │    │             │    │             │
│ Q → A1      │───▶│ Q + A1 → A2 │───▶│ Q + A1 + A2 │
│             │    │             │    │     → A3    │
└─────────────┘    └─────────────┘    └─────────────┘
```

**Hint Accumulation:**
```
Context Size: 1 → 2 → 3 → ... → N
Accuracy:    60% → 75% → 85% → ... → 95%
```

**Multi-Turn Flow:**
```
User: "How to create a function?"
AI:  "def function_name(): return value"
User: "How to add parameters?"
AI:  "def function_name(param1, param2): return param1 + param2"
User: "How to add type hints?"
AI:  "def function_name(param1: int, param2: int) -> int: return param1 + param2"
```

### Cache-Augmented Generation (CAG)

Preloads relevant context into working memory to eliminate real-time retrieval dependencies and reduce latency. Implements memory management strategies including short-term memory for immediate context within sessions and long-term memory for user preferences and past interactions. Enables personalized and contextually aware responses over time through efficient context management.

#### Visual Representation

```mermaid
graph TD
    A[New Input] --> B[Check Cache]
    B --> C{Cache Hit?}
    C -->|Yes| D[Use Cached Context]
    C -->|No| E[Retrieve from Source]
    E --> F[Update Cache]
    F --> D
    D --> G[Generate Response]
    G --> H[Update Memory]
    
    I[Short-term Memory] -.-> B
    J[Long-term Memory] -.-> B
    K[Working Memory] -.-> G
```

**Memory Hierarchy:**
```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Short-term    │    │   Long-term     │    │   Working       │
│   Memory        │    │   Memory        │    │   Memory        │
│   (Session)     │    │   (Preferences) │    │   (Active)      │
│                 │    │                 │    │                 │
│ • Current       │    │ • User Profile  │    │ • Current Task  │
│ • Recent        │    │ • History       │    │ • Context       │
│ • Temporary     │    │ • Patterns      │    │ • State         │
└─────────────────┘    └─────────────────┘    └─────────────────┘
```

**Cache Performance:**
```
Cache Hit:  ~10ms response time
Cache Miss: ~500ms response time
Hit Rate:   85% (typical)
```

**Memory Management:**
```
Input → [Check] → [Hit/Miss] → [Retrieve] → [Generate] → [Update]
  ↓        ↓         ↓           ↓           ↓          ↓
Query → Cache → Context → Response → Memory → Store
```

### Cognitive Scaffolding Prompting

Expanded conception of scaffolding with four key elements: scaffolding agency (expert, reciprocal, and self-scaffolding). Prompts students to construct internal mental models that reflect both prior experiences and cognitive demands of tasks. Framework explores relations between learning and mental models, enabling systematic problem-solving through structured cognitive support.

#### Visual Representation

```mermaid
graph TD
    A[Complex Task] --> B[Expert Scaffolding]
    B --> C[Reciprocal Scaffolding]
    C --> D[Self-Scaffolding]
    D --> E[Mental Model Construction]
    E --> F[Model Validation]
    F --> G{Model Valid?}
    G -->|Yes| H[Apply Model]
    G -->|No| I[Refine Model]
    I --> E
    H --> J[Task Completion]
    
    K[Prior Experience] -.-> E
    L[Cognitive Demands] -.-> E
```

**Scaffolding Levels:**
```
Level 1: Expert Scaffolding (Teacher/Guide)
Level 2: Reciprocal Scaffolding (Peer/Group)
Level 3: Self-Scaffolding (Independent)
Level 4: Mental Model (Internalized)
```

**Mental Model Construction:**
```
┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│   Prior     │    │  Cognitive  │    │   Mental    │
│ Experience  │───▶│   Demands   │───▶│   Model     │
│             │    │             │    │             │
│ • Knowledge │    │ • Task      │    │ • Structure │
│ • Skills    │    │ • Context   │    │ • Process   │
│ • Patterns  │    │ • Goals     │    │ • Rules     │
└─────────────┘    └─────────────┘    └─────────────┘
```

**Scaffolding Agency:**
```
Expert:     Direct instruction, modeling
Reciprocal: Collaborative problem-solving
Self:       Independent reasoning, reflection
```

**Validation Process:**
```
Model → [Test] → [Validate] → [Refine] → [Apply]
  ↓        ↓         ↓          ↓         ↓
Build → Check → Verify → Improve → Use
```

### Advanced Techniques

### Internal Knowledge Synthesis (IKS)

Generates hypothetical knowledge constructs from parametric memory and cross-references internal knowledge consistency for coherent distributed responses. Addresses conflicts between parametric knowledge and context-provided knowledge that can lead to faithfulness issues in LLM generation. Enables coherent knowledge integration across multiple internal domains through fine-grained consistency validation.

#### Visual Representation

```mermaid
graph TD
    A[Input Query] --> B[Parametric Memory]
    B --> C[Generate Knowledge Constructs]
    C --> D[Cross-Reference Consistency]
    D --> E[Resolve Conflicts]
    E --> F[Synthesize Knowledge]
    F --> G[Validate Coherence]
    G --> H{Consistent?}
    H -->|Yes| I[Generate Response]
    H -->|No| J[Refine Constructs]
    J --> D
    I --> K[Final Output]
    
    L[Domain A] -.-> D
    M[Domain B] -.-> D
    N[Domain C] -.-> D
```

**Knowledge Integration:**
```
Parametric Memory → [Generate] → [Cross-Reference] → [Synthesize] → Response
       ↓              ↓              ↓               ↓
   Training Data → Constructs → Consistency → Integration → Output
```

**Multi-Domain Synthesis:**
```
┌─────────────┐  ┌─────────────┐  ┌─────────────┐
│   Domain A  │  │   Domain B  │  │   Domain C  │
│  (Science)  │  │ (History)   │  │ (Culture)   │
└─────────────┘  └─────────────┘  └─────────────┘
       │                │                │
       └─────── Cross-Reference ─────────┘
                        │
                   [Consistency Check]
                        │
                   [Synthesized Knowledge]
```

**Conflict Resolution:**
```
Parametric: "X is true"
Context:    "X is false"
Resolution: "X is conditionally true based on Y"
```

**Consistency Validation:**
```
Level 1: Sentence-level coherence
Level 2: Domain-level consistency
Level 3: Cross-domain integration
Level 4: Global coherence
```

### Multimodal Synthesis

Multimodal Chain-of-Thought (CoT) prompting uses both text and visual inputs to guide model's reasoning process. Particularly effective for tasks requiring interpretation of charts, images, or diagrams, allowing model to reason through both written and visual information. Enables cross-modal analysis for broader complex task solutions by integrating multiple data modalities in reasoning processes.

#### Visual Representation

```mermaid
graph TD
    A[Text Input] --> C[Multimodal Fusion]
    B[Image Input] --> C
    C --> D[Cross-Modal Analysis]
    D --> E[Visual Question Answering]
    E --> F[Reasoning Process]
    F --> G[Synthesize Response]
    G --> H[Final Output]
    
    I[Charts] -.-> B
    J[Diagrams] -.-> B
    K[Photos] -.-> B
```

**Multimodal Processing:**
```
Text + Image → [Fusion] → [Analysis] → [Reasoning] → [Synthesis] → Output
  ↓      ↓        ↓         ↓          ↓           ↓
Query + Visual → Combine → Cross-Modal → CoT → Integrate → Answer
```

**Cross-Modal Analysis:**
```
┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│    Text     │    │   Visual    │    │   Audio     │
│ Processing  │    │ Processing  │    │ Processing  │
└─────────────┘    └─────────────┘    └─────────────┘
       │                  │                  │
       └─────────── Fusion Layer ────────────┘
                        │
                   [Cross-Modal Reasoning]
```

**Visual Question Answering:**
```
Question: "What is shown in this chart?"
Image:    [Bar chart showing sales data]
Process:  Text + Visual → Analysis → Reasoning → Answer
Result:   "The chart shows Q3 sales increased by 15%"
```

**Modality Integration:**
```
Text:     "Analyze this data"
Image:    [Data visualization]
Audio:    [Spoken context]
Output:   "Based on the visual data and audio context..."
```

### Knowledge Synthesis Prompting (KSP)

Integrates multiple internal domains through fine-grained coherence validation for cross-domain knowledge integration. Enables complex factual content synthesis by combining knowledge from different domains while maintaining consistency and accuracy. Particularly effective for tasks requiring comprehensive understanding across multiple knowledge areas.

#### Visual Representation

```mermaid
graph TD
    A[Complex Query] --> B[Domain A Knowledge]
    A --> C[Domain B Knowledge]
    A --> D[Domain C Knowledge]
    
    B --> E[Fine-Grained Validation]
    C --> E
    D --> E
    
    E --> F[Cross-Domain Integration]
    F --> G[Coherence Check]
    G --> H{Consistent?}
    H -->|Yes| I[Synthesize Content]
    H -->|No| J[Refine Integration]
    J --> E
    I --> K[Final Response]
```

**Cross-Domain Integration:**
```
Domain A + Domain B + Domain C → [Validate] → [Integrate] → [Synthesize] → Output
    ↓           ↓           ↓         ↓          ↓           ↓
  Science + History + Culture → Coherence → Combine → Factual → Answer
```

**Knowledge Validation:**
```
┌─────────────┐  ┌─────────────┐  ┌─────────────┐
│   Domain A  │  │   Domain B  │  │   Domain C  │
│  (Science)  │  │ (History)   │  │ (Culture)   │
└─────────────┘  └─────────────┘  └─────────────┘
       │                │                │
       └─────────── Fine-Grained ────────┘
                   Validation
                        │
                   [Coherence Check]
                        │
                   [Synthesized Knowledge]
```

**Integration Process:**
```
Step 1: Extract knowledge from each domain
Step 2: Validate consistency across domains
Step 3: Identify conflicts and resolve
Step 4: Integrate coherently
Step 5: Synthesize final content
```

**Coherence Levels:**
```
Level 1: Sentence-level coherence
Level 2: Domain-level consistency
Level 3: Cross-domain integration
Level 4: Global factual accuracy
```

#### Visual Representation

```mermaid
graph TD
    A[Long Prompt] --> B[Budget Controller]
    B --> C[Coarse Compression]
    C --> D[Fine Compression]
    D --> E[Semantic Validation]
    E --> F[Compressed Prompt]
    
    G[Model Distillation] -.-> B
    H[Tokenizer] -.-> C
    I[Memory Budget] -.-> B
```

**Compression Pipeline:**
```
Original → [Budget] → [Coarse] → [Fine] → [Validate] → Compressed
  100%       ↓         ↓         ↓         ↓
          Control → 50% → 20% → Semantic → 5% Size
```

**Performance Metrics:**
```
Compression: 20x
Performance Loss: <5%
Latency Reduction: 80%
Cost Reduction: 95%
```

**Memory Budget Management:**
```
Input: 10,000 tokens
Budget: 500 tokens (5%)
Strategy: Keep essential, remove redundant
Output: 500 tokens (20x compression)
```

### Compression Strategies

- Preserve reasoning chains while compacting examples
- Use structured formats (XML, JSON) for efficiency
- Apply progressive detail reduction based on relevance

### Consistency Checks

- Verify logical coherence in reasoning chains
- Validate internal knowledge consistency and reliability

### Confidence Calibration

- Explicit uncertainty quantification (0.0-1.0)

### Acronyms REFERENCE

### Core Frameworks

- OOReDAct = Observe-Orient-Reason-Decide-Act
- CUC-N = Complexity, Uncertainty, Consequence, Novelty
- CAG = Cache-Augmented Generation
- IKS = Internal Knowledge Synthesis
- RAG = Retrieval-Augmented Generation
- APO = Automated Prompt Optimization
- MP = Metacognitive Prompting

### Reasoning Methods

- CoD = Chain-of-Draft
- CoT = Chain-of-Thought
- SCoT = Structured Chain-of-Thought  
- ToT = Tree-of-Thoughts
- PAL = Program-Aided Language Models
- ReAct = Reasoning and Acting
- KSP = Knowledge Synthesis Prompting
- PoT = Program-of-Thought
- SC = Self-Consistency
- PHP = Progressive-Hint Prompting
- CSP = Cognitive Scaffolding Prompting

---

Think about these techniques using ≤5 words per cogntigive technique for optimal efficiency.
